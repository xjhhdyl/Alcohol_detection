{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批处理ESD表格，主要把时间戳转化为时间轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dirlist = os.listdir('../CollectedData/BINS/')\n",
    "print(dirlist)\n",
    "for i in dirlist:\n",
    "    data = pd.read_csv('../CollectedData/BINS/'+i)\n",
    "    time_df = data.iloc[:,0] # 获取时间戳的那一列\n",
    "    bins_df = data.iloc[:,1:-1] # 获取bins的列\n",
    "    data['max'] = bins_df.max(axis=1) # 找到bins中每一行的最大值，并且赋值给max列\n",
    "    data['time'] = (time_df-time_df[0])/1000\n",
    "    output = data[['time','max']]\n",
    "    output.to_csv('../CollectedData/OutBINS/out_'+i, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超声波信号和音频信号相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.soundBase import soundBase\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as spi\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "waveform, sample_rate = torchaudio.load('../CollectedData/WAV/SingleWav6.wav') # 读取音频文件\n",
    "# sb = soundBase('../CollectedData/WAV/SingleWav6.wav') # 读取音频文件\n",
    "# audio_data , fs = sb.audioread()\n",
    "esd_df = pd.read_csv('../CollectedData/OutBINS/out_TEST_BINS6.csv') # 读取ESD数据文件\n",
    "esd_time = esd_df['time']\n",
    "esd_data = esd_df['max']\n",
    "# 音频幅值归一化\n",
    "# min_max_scaler1 = MinMaxScaler(feature_range=(-1,1),copy=True) # 定义归一化的范围为[-1,1]\n",
    "# audio_data_minmax = min_max_scaler1.fit_transform(audio_data.reshape(-1,1))\n",
    "# sb.soundplot(audio_data_minmax,sr=fs)\n",
    "\n",
    "plt.plot(esd_time.values,esd_data_minmax)\n",
    "# 音频下采样 很慢，不知道为啥\n",
    "# print(audio_data_minmax.squeeze().shape)\n",
    "# audio_data_minmax_downsampled = librosa.resample(audio_data.astype(np.float32), orig_sr = fs, target_sr = 16000) # 下采样至16Khz\n",
    "\n",
    "# 超声波幅值归一化\n",
    "# min_max_scaler2 = MinMaxScaler(feature_range=(0,1),copy=True) # 定义归一化的范围为[0,1]\n",
    "# esd_data_minmax = min_max_scaler2.fit_transform(esd_data.values.reshape(-1,1))\n",
    "\n",
    "# 超声波上采样\n",
    "# time = [i / 16000 for i in range(len(audio_data_minmax_downsampled.reshape(-1,1)))] # 音频的时间点\n",
    "# ipo1 = spi.splrep(esd_time.values,esd_data_minmax,k=1) # 样本点导入，生成参数\n",
    "# upsample_esd = spi.splev(time,ipo1) # 根据观测点和样条参数，生成插值，观测点设置为音频的时间坐标\n",
    "# # plt.plot(esd_time.values,esd_data_minmax,'o',label='样本点')\n",
    "# # plt.plot(time,upsample_esd,label='插值点')\n",
    "# # plt.ylim(esd_data.values.min(),esd_data.values.max()+1)\n",
    "# # plt.ylabel('指数')\n",
    "# # plt.title('线性插值')\n",
    "# # plt.legend()\n",
    "\n",
    "# multilsignal = np.multiply(upsample_esd,audio_data_minmax_downsampled.reshape(-1,1).squeeze())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相乘信号低通滤波，然后进行谱熵法的端点检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.speechlib import *\n",
    "fs = 16000\n",
    "multilsignal = multilsignal - np.mean(multilsignal)\n",
    "multilsignal = multilsignal / np.max(multilsignal)\n",
    "IS = 0.25\n",
    "wlen = 200\n",
    "inc = 80\n",
    "N = len(multilsignal)\n",
    "time = [i / fs for i in range(N)]\n",
    "wnd = np.hamming(wlen)\n",
    "overlap = wlen - inc\n",
    "NIS = int((IS * fs - wlen) // inc + 1)\n",
    "\n",
    "mode = 1\n",
    "if mode == 1:\n",
    "    thr1 = 1\n",
    "    thr2 = 1.3\n",
    "    tlabel = '能零比'\n",
    "elif mode == 2:\n",
    "    thr1 = 0.05\n",
    "    thr2 = 0.1\n",
    "    tlabel = '能熵比'\n",
    "voiceseg, vsl, SF, NF, Epara = vad_pro(multilsignal, wnd, inc, NIS, thr1, thr2, mode)\n",
    "\n",
    "fn = len(SF)\n",
    "frameTime = FrameTimeC(fn, wlen, inc, fs)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, multilsignal)\n",
    "plt.title('相乘信号波形')\n",
    "plt.ylabel('幅值')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(frameTime, Epara)\n",
    "plt.title(tlabel)\n",
    "plt.xlabel('时间/s')\n",
    "plt.ylabel('幅值')\n",
    "\n",
    "for i in range(vsl):\n",
    "    nx1=voiceseg[i]['start']\n",
    "    nx2=voiceseg[i]['end']\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.axvline(frameTime[nx1], np.min(multilsignal), np.max(multilsignal), color='blue', linestyle='--')\n",
    "    plt.axvline(frameTime[nx2], np.min(multilsignal), np.max(multilsignal), color='red', linestyle='-')\n",
    "    plt.legend(['波形', '起点', '终点'])\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.axvline(frameTime[nx1], np.min(Epara), 1.0, color='blue', linestyle='--')\n",
    "    plt.axvline(frameTime[nx2], np.min(Epara), 1.0, color='red', linestyle='-')\n",
    "    plt.legend([tlabel, '起点', '终点'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load('WAV/sober/SingleWav1.wav') # 读取音频文件\n",
    "print(sample_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "345ce40e20285f5c7c7977ee44d83041e0c9233e1ba1336e7d41f9ca60463eaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
